---
title: "Clear Minds Think Alike: What Makes LLM Fine-tuning Robust? A Study of Token Perplexity"
collection: publications
permalink: /publication/2025-01-27-stm
excerpt: 'A systematic analysis revealing that fine-tuning with LLM-generated data not only improves target task performance but also reduces out-of-domain degradation compared to fine-tuning with ground truth data and ways to mitigate it'
date: 2025-01-27
category: conferences
venue: 'arXiv'
paperurl: 'https://arxiv.org/abs/2501.14315'
citation: 'Wu, C.C., Tam, Z.R., Lin, C.Y., Lee, H.Y., & Chen, Y.N. (2025). "Clear Minds Think Alike: What Makes LLM Fine-tuning Robust? A Study of Token Perplexity." arXiv preprint arXiv:2501.14315.'
---

<a href='https://arxiv.org/abs/2501.14315'>Download paper here</a>

Maintaining consistent model performance across domains is a fundamental challenge in machine learning. While recent work has explored using LLM-generated data for fine-tuning, its impact on cross-domain generalization remains poorly understood. Our work presented a systematic analysis revealing that fine-tuning with self-generated data not only improves target task performance but also reduces out-of-domain degradation compared to fine-tuning with ground truth data. But this is costly due to the pre-sampling phase, I purpose instead just train on ground truth tokens which has low perplexity by constructing a mask on autoregressive objective.

Recommended citation: Wu, C.C., Tam, Z.R., Lin, C.Y., Lee, H.Y., & Chen, Y.N. (2025). "Clear Minds Think Alike: What Makes LLM Fine-tuning Robust? A Study of Token Perplexity." arXiv preprint arXiv:2501.14315.